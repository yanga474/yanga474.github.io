<html> 
    <head> 
        <title>Reading Response 4</title>
    </head>

    	<h2 align="center" style="font-family:futura">Reading Response - How Reporting and Moderation On Social Media is Failing Marginalized Groups  </h1>

    <body>
   


        <p align="center" style="font-family:cambria">
       	In stage one, it explains something called reverse racism means “they are often poorly suited to make decisions about content that affects marginalized people.” This is not the first time I’ve heard the terms reverse racism. It is a course that is taught in many colleges around the United States. I always thought the course topic to be pretentious and the concept does not address racism issues to the fullest. It’s interesting how this article uses this term to address the racism within social media. Not only that, it’s insane that big social media sites like Twitter and Facebook has such a big platform to reduce racism but when users report explicit threats of violence, they are told that it doesn’t represent a terms of service violation. “In order to create and execute policy more effectively, social platforms would need to take steps to address not just the content of their policies, but how policies and reporting mechanisms can themselves be weaponized by privileged users — particularly White users — against users of color. “ This is a quote taken from the article and I agree with this 100 percent, social platforms need to set address these issues head on and with more detail. In the third stage of the article, it states the user reports are pushed through an algorithm and deleted. However only 90% of the hate speech is caught, the other 10% can “may still unjustly capture people pages who are speaking academically about harassment and abuse.” This raises the question on who designs these algorithms and how it affects those who are marginalized. 

		</p>
         


    </body>
</html>

